2.84+.4/sqrt(40)
qnorm(0.95)
qt(0.95,39)
qt(0.95,19)
2.84+0.4/sqrt(20)*qt(0.95,19)
2.84-0.4/sqrt(20)*qt(0.95,19)
2.84-0.4/sqrt(40)*qt(0.95,19)
2.84+0.4/sqrt(40)*qt(0.95,39)
2.84-0.4/sqrt(40)*qt(0.95,39)
2.84+0.4/sqrt(40)*qnorm(0.95)
2.84-0.4/sqrt(15)*qt(0.95,14)
2.84+0.4/sqrt(15)*qt(0.95,14)
2.84+0.4/sqrt(60)*qt(0.95,59)
2.84-0.4/sqrt(60)*qt(0.95,59)
qnorm(0.995)
qnorm(0.99)
qt(p = 0.05,df = 35)
qt(p = 0.01,df = 35)
qt(p = 0.99,df = 35)
qt(p = 0.995,df = 35)
qt(p = 0.99,df = 35)
qt(p = 0.99,df = 350)
qt(p = 0.99,df = 35)
149750-145000
4750/24000/6
24000/6
4750/24000*6
29*325^2/300^2
qnorm(0.995)
qnorm(0.95)
?pbinom
dbinom(0,3,0.5)
dbinom(1,3,0.5)
dbinom(2,3,0.5)
dbinom(3,3,0.5)
4/11/10/9
sqrt(35/3)
x = -99999999:0
sum(-4/81*(x^4/4 - 9*x^2/2))
500*0.5*0.5
sqrt(125)
(260-250)/sqrt(125)
(260-250)/sqrt(125)*2
(260-250)/sqrt(125)
pnorm(0)
pnorm(0.8944272)-pnorm(-0.8944272)
pnorm(-0.8944272)
pnorm(0.8944272)-pnorm(-0.8944272)
(280-250)/sqrt(125)
pnorm(2.683282)-pnorm(-2.683282)
?binom
pbinom
?pbinom
pbinom(2,10,0.1)
9*10/2*0.01*0.9^8
dbinom(2,10,0.1)
0.5*exp()
0.5*exp(1)
0.5*exp(-1)
0.1937102-0.1839397
2*10*0.1^2
5^3*4^2*3^2*5*3/126
5^3*4^2*3^2*5*3/12^6
-0.04/(1/12/sqrt(200))
sqrt(0.55*0.45/100)
sqrt(0.55*0.45/100)*1.96+0.55
(64*39+49*49)/88
sqrt(55.64775)
sqrt(55.64773)
sqrt(9/200)
4/(7.45*0.21)
pow(2,4)
1616^2
1625^2
3625^2
1625^2
2625^2
8125^2
2525^2
251^2
2511^2
(1:99)^2
(1:99)^2-1:99
rbind(1:99,(1:99)^2-1:99)
cbind(1:99,(1:99)^2-1:99)
1376^2
3676^2
2576^2
1176^2
676^2
176^2
276^2
376^2
476^2
576^2
676^2
776^2
876^2
976^2
925^2
825^2
725^2
625^2
1625
1625^2
2625^2
3625^2
4625^2
5625^2
6625^2
7625^2
8625^2
9625^2
9625^2
1625^2
25^2
76^2
176^2
276^2
376^2
1376
1376^2
2376^2
3376^2
4376^2
5376^2
6376^2
7376^2
8376^2
9376^2
pnorm(1.0729)
pnorm(0.9979)
4/52 * 3/51 / 50 / 49/ 48/ 47/ 46/ 45/ 44/ 43/ 42/ 41
x = c(89, 72, 94, 69)
x
mean(x)
x - mean(x)
(x - mean(x)) / (max(x) - min(x))
log(0.5)
-log(0.5)
25*28
1945+2010
2010+2385
4395-3955
4*2.5*2
28*250
1.5*1.5
3*2*1.5
6*4*18
432/9
60*40*18
60*40*18/9
2745/2495
165000*0.7
112/48
95/110
195/110500
19500/110500
195000/110500
1.044*(1-0.028)
1.035^3
1.05^5
1.03*1.05*1.04*1.06
log(10)
sd(c(5,8,12))
which.min(c(4,1,6))
2x = 4
s2.r = 5
summary(s2.r)
str(s2.r)
getwd()
getwd()
Google DeepMind
fit <- lm(mpg~hp, data=mtcars)
summary(fit)
residuals(fit)
sum(residuals(fit)^2)
sqrt(sum(residuals(fit)^2))
sqrt(sum(residuals(fit)^2)/30)
mtcars$mpg
summary(mtcars$mpg)
str(mtcars$mpg)
?sample.int
?with
1 - 18/24
getwd()
wine = read.csv('Dropbox/Education/edX/The Analytics Edge/Unit 2/Data/wine.csv')
lm1 = lm(Price ~ HarvestRain + WinterRain)
lm1 = lm(Price ~ HarvestRain + WinterRain, data = wine)
summary(lm1)
cor(wine$HarvestRain, wine$WinterRain)
baseball = read.csv('Dropbox/Education/edX/The Analytics Edge/Unit 2/Data/baseball.csv')
baseball$RD = baseball$RS - baseball$RA
lm1 = lm(W ~ RD, data = baseball)
summary(lm1)
baseball = baseball[baseball$Year < 2002]
baseball = baseball[baseball$Year < 2002,]
lm1 = lm(W ~ RD, data = baseball)
sum(lm1)
summary(lm1)
713 - 614
predict(lm1, newdata = data.frame(RD = 99))
data.frame(RD = 99)
predict(lm1, newdata = data.frame(RD = 133))
str(baseball)
lm2 = lm(RS = OBP + SLG)
lm2 = lm(RS = OBP + SLG, data = baseball)
lm2 = lm(RS ~ OBP + SLG, data = baseball)
summary(lm2)
predict(lm2, newdata = data.frame(OBP = 0.311, SLG = 0.405))
data.frame(OBP = 0.311, SLG = 0.405)
lm3 = lm(RA ~ OOBP + OSLG, data = baseball)
predict(lm3, newdata = data.frame(OOBP = 0.297, OSLG = 0.370))
predict(lm2, newdata = data.frame(OBP = c(0.338, 0.391, 0.369, 0.313, 0.361), SLG = c(0.54, 0.45, 0.374, 0.447, .5)))
teamRank = c(1,2,3,3,4,4,4,4,5,5)
wins2012 = c(94, 88, 95, 88, 93, 94, 98, 97, 93,94)
wins2013 = c(97,97,92,93,92,96,94,96,92,90)
cor(teamRank, wins2012)
cor(teamRank, wins2013)
setwd("~/Dropbox/Education/edX/The Analytics Edge/Unit 2")
##### CLIMATE CHANGE #####
### Problem 1 - Loading the Data ###
clmt = read.csv("climate_change.csv")
clmt = read.csv("Data/climate_change.csv")
clmt
clmt_train = subset(clmt, clmt$Year <= 2006)
clmt_test = subset(clmt, clmt$Year > 2006)
setwd("~/Dropbox/Education/edX/The Analytics Edge/Unit 2")
##### CLIMATE CHANGE #####
### Problem 1 - Loading the Data ###
clmt = read.csv("Data/climate_change.csv")
clmt_train = subset(clmt, clmt$Year <= 2006)
clmt_test = subset(clmt, clmt$Year > 2006)
str(clmt_train)
lm1 = lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data = clmt_train)
summary(lm1)
corr(clmt_train)
cor(clmt_train)
lm1 = lm(Temp ~ MEI + N2O + TSI + Aerosols, data = clmt_train)
lm1 = lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data = clmt_train)
lm2 = lm(Temp ~ MEI + N2O + TSI + Aerosols, data = clmt_train)
summary(lm2)
lm3 = step(lm1)
summary(lm3)
summary(lm1)
summary(lm3)
?pred
pred = predict(lm3, newdata = clmt_test)
clmt_test
setwd("~/Dropbox/Education/edX/The Analytics Edge/Unit 2")
##### CLIMATE CHANGE #####
### Problem 1 - Creating Our First Model ###
clmt = read.csv("Data/climate_change.csv")
clmt_train = subset(clmt, clmt$Year <= 2006)
clmt_test = subset(clmt, clmt$Year > 2006)
lm1 = lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data = clmt_train)
summary(lm1)
### Problem 2 - Understanding the Model ###
cor(clmt_train)
### Problem 3 - Simplifying the Model ###
lm2 = lm(Temp ~ MEI + N2O + TSI + Aerosols, data = clmt_train)
summary(lm2)
### Problem 4 - Automatically Building the Model ###
lm3 = step(lm1)
summary(lm3)
pred = predict(lm3, newdata = clmt_test)
pred
SSE = sum((clmt_test$Temp - pred)^2)
SST = sum((clmt_test$Temp - mean(clmt_test$Temp))^2)
R2 = 1 - SSE/SST
R2
SST = sum((clmt_test$Temp - mean(clmt_train$Temp))^2)
R2 = 1 - SSE/SST
SST = sum((clmt_test$Temp - mean(clmt_test$Temp))^2)
SST = sum((clmt_test$Temp - mean(clmt_train$Temp))^2)
R2 = 1 - SSE/SST
pisaTrain = read.csv("Data/pisa2009train.csv")
pisaTest = read.csv("Data/pisa2009test.csv")
str(pisaTrain)
tapply(pisaTrain$readingScore, pisaTrain$male, mean)
pisaTrain(isnull(pisaTrain))
pisaTrain[isnull(pisaTrain)]
isna(pisaTrain)
is.na(pisaTrain)
is.na(pisaTrain)>1
is.na(pisaTrain)
summary(pisaTrain)
### Problem 1.4 - Removing missing values ###
pisaTrain = na.omit(pisaTrain)
pisaTest = na.omit(pisaTest)
str(pisaTrain)
str(pisaTest)
### Problem 1.4 - Removing missing values ###
summary(pisaTest)
summary(pisaTrain)
summary(pisaTrain$grade)
str(pisaTrain$grade)
str(as.factor(pisaTrain$grade))
str(as.factor(pisaTrain$grade))
str(as.factor(pisaTrain$grade))
str(as.factor(pisaTrain$male))
str(as.factor(pisaTrain$raceeth))
str(as.factor(pisaTrain$raceeth))
summary(as.factor(pisaTrain$raceeth))
lm2$anova
str(pisaTrain)
pisaTrain$raceeth = relevel(pisaTrain$raceeth, "White")
pisaTest$raceeth = relevel(pisaTest$raceeth, "White")
pisaTrain$raceeth = relevel(pisaTrain$raceeth, "White")
str(pisaTrain)
lmScore = lm(readingScore ~ ., data = pisaTrain)
summary(lmScore)
SSE = sum((lmScore$residuals)^2)
RMSE = SSE / nrow(pisaTrain)
RMSE
RMSE = sqrt(SSE / nrow(pisaTrain))
RMSE
summary(lmScore)
pred = predict(lmScore, newdata = pisaTest)
summary(pred)
)
max(pred) - min(pred)
range = max(pred) - min(pred)
SSE = sum((lmScore$residuals)^2)
SSE
RMSE = sqrt(SSE / nrow(pisaest))
RMSE = sqrt(SSE / nrow(pisaTest))
TMSE
RMSE
SSE = sum((pisaTest$readingScore - pred)^2)
RMSE = sqrt(SSE / nrow(pisaTest))
SSE
RMSE
mean(pisaTrain$readingScore)
baseline = mean(pisaTrain$readingScore)
SST = sum((pisaTest$readingScore - baseline)^2)
SST
R2 = 1 - SSE/SST
R2
FluTrain = read.csv("Data/FluTrain.csv")
FluTrain
sort(table(FluTrain$ILI, FluTrain$Week))
sort(FluTrain)
subset(FluTrain, ILI == max(ILI))
FluTrain$Week[which.max(FluTrain$ILI)]
subset(FluTrain, ILI == max(Queries))
subset(FluTrain, Quaries == max(Queries))
subset(FluTrain, Queries == max(Queries))
hist(FluTrain$ILI)
plot(FluTrain$ILI, FluTrain$Queries)
plot(log(FluTrain$ILI), FluTrain$Queries)
plot(FluTrain$Queries, log(FluTrain$ILI))
FluTrend1 = lm(log(ILI) ~ Queries, data = FluTrain)
summary(FluTrend1)
cor(FluTrain$Queries, FluTrain$ILI)
cor(FluTrain$Queries, FluTrain$ILI)^2
r = cor(FluTrain$Queries, FluTrain$ILI)
r^2
log(1/r)
exp(-0.5*r)
r = cor(FluTrain$Queries, log(FluTrain$ILI))
r^2
log(1/r)
exp(-0.5*r)
FluTest = read.csv("Data/FluTest.csv")
PredTest1 = exp(predict(FluTrend1, newdata=FluTest))
summary(PredTest1)
FluTest
which(FluTest$Week == "2012-03-11 - 2012-03-17")
FluTest[which(FluTest$Week == "2012-03-11 - 2012-03-17")]
FluTest[which(FluTest$Week == "2012-03-11 - 2012-03-17"), ]
PredTest2 = exp(predict(FluTrend1, newdata=FluTest[which(FluTest$Week == "2012-03-11 - 2012-03-17"), ]))
PredTest2
PredTest1[FluTest[which(FluTest$Week == "2012-03-11 - 2012-03-17"), ]]
PredTest1[which(FluTest$Week == "2012-03-11 - 2012-03-17")]
relativeError = (PredTest1 - FluTest$ILI)/FluTest$ILI
relativeError
relativeError[which(FluTest$Week == "2012-03-11 - 2012-03-17")]
relativeError = (FluTest$ILI - PredTest1)/FluTest$ILI
relativeError[which(FluTest$Week == "2012-03-11 - 2012-03-17")]
SSE = sum((FluTest$ILI - PredTest1)^2)
RMSE = sqrt(SSE / nrow(FluTest))
RMSE
library(zoo)
ILILag2 = lag(zoo(FluTrain$ILI), -2, na.pad=TRUE)
ILILag2
?coredata
FluTrain$ILILag2 = coredata(ILILag2)
head(FluTrain)
tai(FluTrain)
tail(FluTrain)
FluTrain$ILILag2 = coredata(ILILag2)
summary(FluTrain)
plot(log(FluTrain$ILI), log(FluTrain$ILILag2))
FluTrend1 = lm(log(ILI) ~ Queries + log(ILILag2), data = FluTrain)
FluTrend1 = lm(log(ILI) ~ Queries, data = FluTrain)
FluTrend2 = lm(log(ILI) ~ Queries + log(ILILag2), data = FluTrain)
summary(FluTrend2)
ILILag2 = lag(zoo(FluTest$ILI), -2, na.pad=TRUE)
FluTest$ILILag2 = coredata(ILILag2)
summary(FluTest$ILILag2)
FluTest$ILILag2[1] = FluTrain$ILI[416]
FluTest$ILILag2[2] = FluTrain$ILI[417]
head(fultest)
head(FluTest)
PredTest2 = exp(predict(FluTrend2, newdata=FluTest))
SSE = sum((FluTest$ILI - PredTest2)^2)
RMSE = sqrt(SSE / nrow(FluTest))
RMSE
SSE = sum((FluTest$ILI - PredTest1)^2)
RMSE = sqrt(SSE / nrow(FluTest))
SSE = sum((FluTest$ILI - PredTest2)^2)
RMSE = sqrt(SSE / nrow(FluTest))
data(state)
str(statedata)
str(statedata)
data(statedata)
View(state.x77)
str(state)
data(state)
statedata = cbind(data.frame(state.x77), state.abb, state.area, state.center,
state.division, state.name, state.region)
statedata
plot(statedata$x, statedata$y)
plot(statedata$x, statedata$y, type = "l")
plot(statedata$x, statedata$y)
tapply(statedata$HS.Grad, statedata$state.region, max)
tapply(statedata$HS.Grad, statedata$state.region, mean)
plot(statedata$Murder, statedata$state.region)
plot(statedata$state.region, statedata$Murder)
NortheastData = subset(statedata, state.region == "Northeast")
NortheastData
NortheastData$state.abb[which.max(NortheastData$Murder)]
lm1 = lm(Life.Exp ~ Population + Income + Illiteracy + Murder, HS.Grad + Frost + Area, data = statedata)
lm1 = lm(Life.Exp ~ Population + Income + Illiteracy + Murder + HS.Grad + Frost + Area, data = statedata)
summary(lm1)
plot(statedata$Income, statedata$Life.Exp)
summary(lm1)
lm2 = lm(Life.Exp ~ Population + Income + Illiteracy + Murder + HS.Grad + Frost, data = statedata)
summary(lm2)
lm3 = lm(Life.Exp ~ Population + Income + Murder + HS.Grad + Frost, data = statedata)
summary(lm3)
lm4 = lm(Life.Exp ~ Population + Murder + HS.Grad + Frost, data = statedata)
summary(lm4)
summary(lm1)
predTrain = predict(lm4)
predtrain
predTrain
sort(predTrain)
statedata$state.name
statedata$state.name[which.min(statedata$Life.Exp)]
sort(predTrain)
statedata$state.name[which.max(statedata$Life.Exp)]
lm4$residuals
sort(lm4$residuals)
sort(abs(lm4$residuals))
sort(abs(statedata$Life.Exp - predict(model)))
sort(abs(statedata$Life.Exp - predict(lm4)))
elantra = read.csv("Data/elantra.csv")
elantraTrain = subset(elantra, elantra$Year <= 2002)
elantraTest = subset(elantra, elantra$Year > 2002)
lm1 = lm(ElantraSales ~ Unemployment + CPI_all + CPI_energy + Queries, data = elantraTrain)
elantraTrain = subset(elantra, elantra$Year <= 2012)
elantraTest = subset(elantra, elantra$Year > 2012)
### Problem 2.1 - A Linear Regression Model ###
lm1 = lm(ElantraSales ~ Unemployment + CPI_all + CPI_energy + Queries, data = elantraTrain)
summary(lm1)
### Problem 3.1 - Modeling Seasonality ###
lm1 = lm(ElantraSales ~ Month + Unemployment + CPI_all + CPI_energy + Queries, data = elantraTrain)
lm1 = lm(ElantraSales ~ Unemployment + CPI_all + CPI_energy + Queries, data = elantraTrain)
summary(lm2)
lm2 = lm(ElantraSales ~ Month + Unemployment + CPI_all + CPI_energy + Queries, data = elantraTrain)
summary(lm2)
?pairs
pairs(elantra)
elantraTrain$Month = as.factor(elantraTrain$Month)
elantraTest$Month = as.factor(elantraTest$Month)
lm3 = lm(ElantraSales ~ Month + Unemployment + CPI_all + CPI_energy + Queries, data = elantraTrain)
summary(lm3)
cor(elantraTrain)
cor(as.numeric(elantraTrain))
cor(ElantraTrain[c("Unemployment","Month","Queries","CPI_energy","CPI_all")])
cor(elantraTrain[c("Unemployment","Month","Queries","CPI_energy","CPI_all")])
cor(elantraTrain[c("Unemployment","Queries","CPI_energy","CPI_all")], as.numeric(elantraTrain$Month))
cor(elantraTrain[c("Unemployment","Queries","CPI_energy","CPI_all")])
elantraTrain$Month = as.numeric(elantraTrain$Month)
elantraTrain$Month = as.numeric(elantraTrain$Month)
cor(elantraTrain[c("Unemployment","Month","Queries","CPI_energy","CPI_all")])
summary(lm3)
lm3 = lm(ElantraSales ~ Month + Unemployment + CPI_all + CPI_energy + Queries, data = elantraTrain)
summary(lm3)
elantraTrain$Month = as.numeric(elantraTrain$Month)
cor(elantraTrain[c("Unemployment","Month","Queries","CPI_energy","CPI_all")])
elantraTrain$Month = as.factor(elantraTrain$Month)
### Problem 6 - A Reduced Model ###
lm3 = lm(ElantraSales ~ Month + Unemployment + CPI_all + CPI_energy + Queries, data = elantraTrain)
summary(lm3)
lm4 = lm(ElantraSales ~ Month + Unemployment + CPI_all + CPI_energy, data = elantraTrain)
summary(lm4)
pred = predict(lm4, newdata = elantraTest)
SSE = sum((elantraTest$ElantraSales - pred)^2)
SSE
baseline = mean(elantraTrain$ElantraSales)
baseline
SST = sum((elantraTest$ElantraSales - baseline)^2)
R2 = 1 - SSE/SST
R2
errors = elantraTest$ElantraSales - pred
abs(errors)
sort(abs(errors))
elantraTest[which.max(errors)]
elantraTest[which.max(errors), ]
